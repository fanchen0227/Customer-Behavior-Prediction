{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scotiabank Technical Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                        Peter Chen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am provided with more than 1 year of customer product data. The objective is to predict what accounts a customer will acquire in the next month, 2016-05.\n",
    "\n",
    "The case has the three characters: 1) multi-label 2)time-series 3)Unbalanced and Large dataset.\n",
    "\n",
    "1) There are 23 labels. One client can have several labels in the same time. It's a multi-label problem, but I decide to train 23 models for each of the labels. If we use multi-label model, when the model trains, the feature importance may affected by different labels, which lead to a bad performance. Also, the unbalanced distribution of labels will affect training. The selected features will be domained by the labels with high frequency.\n",
    "\n",
    "\n",
    "2) A time-series probelm. Historic accounts information can be used to predict future accounts status. I generate the features of date -- when did the client open the account. The feature could not only used to filter the training and prediction set, but also for prediction. That is to say, if the client open the account before, we should not add them into the training set, because he won't add(it's an action) the account any more. Also, when we choose training set and validation set, we need to focus on the time. Here, I use 2015-03 as training set, use 2015-04 as validation set. When we try to make a prediction of 2015-05.\n",
    "\n",
    "\n",
    "3) The dataset covers clients and 16 months data, which is more than 3GB. The accounts type data are very unbalanced.I build random forest, and use 'class_weight' to ajust the class.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import math\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is to predict what accounts a customer will add in the next month. 'Add' is a event.\n",
    "We define our target Y: {1: The costomer add the account, 0: the customer doesn't add the account}\n",
    "Note: when we train the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data is a large data set. In this notebook, I extract 10,000 sample clients randomly from the client list. Then the analysis can be done in my own computer and run the model locally. After that, I transfer the code on Google Cloud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read test data\n",
    "df_test = pd.read_csv('test/test_monthly_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_accounts = pd.read_csv('sliced_accounts.csv').drop('Unnamed: 0',axis=1)\n",
    "df_train_info=pd.read_csv('sliced_info.csv').drop(['Unnamed: 0','sex_bin'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_train_accounts = pd.read_csv('sliced_accounts.csv').drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_train_info=pd.read_csv('sliced_info.csv').drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cust_id                 int64\n",
       "date                   object\n",
       "employee_index         object\n",
       "country                object\n",
       "sex                    object\n",
       "age                    object\n",
       "open_date              object\n",
       "last_6_months_flag    float64\n",
       "seniority              object\n",
       "primary               float64\n",
       "last_date_primary      object\n",
       "customer_type          object\n",
       "customer_relation      object\n",
       "domestic_index         object\n",
       "foreigner_index        object\n",
       "spouse_index           object\n",
       "channel                object\n",
       "deceased_status        object\n",
       "primary_address       float64\n",
       "province_code         float64\n",
       "province_name          object\n",
       "activity_index        float64\n",
       "gross_income          float64\n",
       "segment                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type\n",
    "df_train_info.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cust_id                    0\n",
       "date                       0\n",
       "employee_index           367\n",
       "country                  367\n",
       "sex                      367\n",
       "age                        0\n",
       "open_date                367\n",
       "last_6_months_flag       367\n",
       "seniority                  0\n",
       "primary                  367\n",
       "last_date_primary     133885\n",
       "customer_type           1610\n",
       "customer_relation       1610\n",
       "domestic_index           367\n",
       "foreigner_index          367\n",
       "spouse_index          134059\n",
       "channel                 1985\n",
       "deceased_status          367\n",
       "primary_address          367\n",
       "province_code           1205\n",
       "province_name           1205\n",
       "activity_index           367\n",
       "gross_income           27005\n",
       "segment                 2015\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_info.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean data missing value of age and seniority and transform into numerical data.\n",
    "# replace missing value by average\n",
    "df_train_info['age']=df_train_info['age'].replace(' NA','-1')\n",
    "df_train_info['seniority']=df_train_info['seniority'].replace(' NA','-1')\n",
    "df_train_info['seniority']=df_train_info['seniority'].replace('     NA','-1')\n",
    "df_train_info['age']=df_train_info['age'].astype('int')\n",
    "df_train_info['seniority']=df_train_info['seniority'].astype('int')\n",
    "df_train_info['age']=df_train_info['age'].replace(-1,df_train_info['age'].mean())\n",
    "df_train_info['seniority']=df_train_info['seniority'].replace(-1,df_train_info['seniority'].mean())\n",
    "#fill the missing values of gross_income by average\n",
    "df_train_info['gross_income']=df_train_info['gross_income'].fillna(df_train_info['gross_income'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Before dealing with other missing value, generate a new features which is the difference of last_date_primary and date.\n",
    "#The new feature day_diff reflects how many days the clients has not been primary.\n",
    "df_train_info['date']=pd.to_datetime(df_train_info['date'])\n",
    "df_train_info['open_date']=pd.to_datetime(df_train_info['open_date'])\n",
    "df_train_info['last_date_primary']=pd.to_datetime(df_train_info['last_date_primary'])\n",
    "df_train_info['day_diff_primary']=(df_train_info['date']-df_train_info['last_date_primary']).fillna(0).map(lambda x: int(x.days/30))\n",
    "df_train_info['day_diff_open']=(df_train_info['date']-df_train_info['open_date']).fillna(0).map(lambda x: int(x.days/30))\n",
    "df_train_info['date']=df_train_info['date'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# age, seniority and gross_income are three useful numerical data. We need to do segmentation for better features.\n",
    "# After one-hot encoding, they will become binary features.\n",
    "def age_bin(age): # age is classifed by life cycle\n",
    "    if age<18:\n",
    "        return 0\n",
    "    elif age>=18 and age <23:\n",
    "        return 1\n",
    "    elif age>=23 and age < 30:\n",
    "        return 2\n",
    "    elif age>=30 and age <40:\n",
    "        return 4\n",
    "    elif age>=40 and age <=60:\n",
    "        return 5\n",
    "    elif age>60:\n",
    "        return 6\n",
    "def seniority_bin(seniority): # seniority is classifed by customer life cycle\n",
    "    if seniority ==0:\n",
    "        return 0\n",
    "    elif seniority <3 and seniority >0:\n",
    "        return 1\n",
    "    elif seniority> 3 and seniority<=6:\n",
    "        return 2\n",
    "    elif seniority ==6:\n",
    "        return 3\n",
    "    elif seniority>6 and seniority<12:\n",
    "        return 4\n",
    "    elif seniority ==12:\n",
    "        return 5\n",
    "    elif seniority >12:\n",
    "        return 6\n",
    "def income_bin(gross_income): # income is classifed by percentiles\n",
    "    if gross_income < 76403:\n",
    "        return 0\n",
    "    elif gross_income >= 76403 and gross_income<123231:\n",
    "        return 1\n",
    "    elif gross_income >= 123231 and gross_income<136899:\n",
    "        return 2\n",
    "    elif gross_income > 136899:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# day_diff_open feature shows whether clients who open the account in one months.\n",
    "df_train_info['day_diff_open']=X_block_14['day_diff_open'].apply(lambda x: 1 if x<31 else 0 )\n",
    "# Apply bin functions\n",
    "df_train_info['age_bin']=X_block_14['age'].apply(age_bin)\n",
    "df_train_info['seniority_bin']= X_block_14['seniority'].apply(seniority_bin)\n",
    "df_train_info['income_bin']= X_block_14['gross_income'].apply(income_bin)\n",
    "df_train_info=X_block_14.drop(['age','seniority','province_code'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill all missing values with categorial features with -1. Then do one-hot encoding. \n",
    "df_train_info=df_train_info.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One-hot encoding for features of client information.\n",
    "df_train_info2=pd.get_dummies(df_train_info, columns = ['employee_index', 'country', 'sex',\n",
    "        'last_6_months_flag', 'primary',\n",
    "       'customer_type', 'customer_relation',\n",
    "       'domestic_index', 'foreigner_index', 'spouse_index', 'channel',\n",
    "       'deceased_status', 'primary_address','province_name',\n",
    "       'activity_index', 'segment','age_bin', 'seniority_bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>date</th>\n",
       "      <th>employee_index</th>\n",
       "      <th>country</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>open_date</th>\n",
       "      <th>last_6_months_flag</th>\n",
       "      <th>seniority</th>\n",
       "      <th>primary</th>\n",
       "      <th>...</th>\n",
       "      <th>channel</th>\n",
       "      <th>deceased_status</th>\n",
       "      <th>primary_address</th>\n",
       "      <th>province_code</th>\n",
       "      <th>province_name</th>\n",
       "      <th>activity_index</th>\n",
       "      <th>gross_income</th>\n",
       "      <th>segment</th>\n",
       "      <th>day_diff_primary</th>\n",
       "      <th>day_diff_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1367111</td>\n",
       "      <td>2015-07-28</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2014-12-09 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>KHE</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MADRID</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48574.8</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1367111</td>\n",
       "      <td>2015-08-28</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2014-12-09 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>KHE</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MADRID</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48574.8</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_id        date employee_index country sex   age            open_date  \\\n",
       "0  1367111  2015-07-28              N      ES   V  25.0  2014-12-09 00:00:00   \n",
       "1  1367111  2015-08-28              N      ES   V  25.0  2014-12-09 00:00:00   \n",
       "\n",
       "   last_6_months_flag  seniority  primary      ...       channel  \\\n",
       "0                 0.0        7.0      1.0      ...           KHE   \n",
       "1                 0.0        8.0      1.0      ...           KHE   \n",
       "\n",
       "  deceased_status primary_address province_code province_name activity_index  \\\n",
       "0               N             1.0          28.0        MADRID            0.0   \n",
       "1               N             1.0          28.0        MADRID            0.0   \n",
       "\n",
       "  gross_income             segment  day_diff_primary  day_diff_open  \n",
       "0      48574.8  03 - UNIVERSITARIO                 0              7  \n",
       "1      48574.8  03 - UNIVERSITARIO                 0              8  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_info.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>age</th>\n",
       "      <th>last_6_months_flag</th>\n",
       "      <th>seniority</th>\n",
       "      <th>primary</th>\n",
       "      <th>primary_address</th>\n",
       "      <th>province_code</th>\n",
       "      <th>activity_index</th>\n",
       "      <th>gross_income</th>\n",
       "      <th>day_diff_primary</th>\n",
       "      <th>day_diff_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.340850e+05</td>\n",
       "      <td>134085.000000</td>\n",
       "      <td>134085.000000</td>\n",
       "      <td>134085.000000</td>\n",
       "      <td>134085.000000</td>\n",
       "      <td>134085.000000</td>\n",
       "      <td>134085.000000</td>\n",
       "      <td>134085.000000</td>\n",
       "      <td>1.340850e+05</td>\n",
       "      <td>134085.000000</td>\n",
       "      <td>134085.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.264522e+05</td>\n",
       "      <td>40.195903</td>\n",
       "      <td>0.058112</td>\n",
       "      <td>80.078843</td>\n",
       "      <td>1.140702</td>\n",
       "      <td>0.994526</td>\n",
       "      <td>26.291353</td>\n",
       "      <td>0.462878</td>\n",
       "      <td>1.340974e+05</td>\n",
       "      <td>-0.000582</td>\n",
       "      <td>81.670425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.304682e+05</td>\n",
       "      <td>17.091791</td>\n",
       "      <td>0.245377</td>\n",
       "      <td>66.211474</td>\n",
       "      <td>3.783715</td>\n",
       "      <td>0.104491</td>\n",
       "      <td>13.084682</td>\n",
       "      <td>0.504081</td>\n",
       "      <td>1.778989e+05</td>\n",
       "      <td>0.047455</td>\n",
       "      <td>68.020026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.589800e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>7.445640e+03</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.457010e+05</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.640391e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.251050e+05</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.232311e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.192617e+06</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.368992e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.547874e+06</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.658967e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>259.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cust_id            age  last_6_months_flag      seniority  \\\n",
       "count  1.340850e+05  134085.000000       134085.000000  134085.000000   \n",
       "mean   8.264522e+05      40.195903            0.058112      80.078843   \n",
       "std    4.304682e+05      17.091791            0.245377      66.211474   \n",
       "min    1.589800e+04       2.000000           -1.000000       0.000000   \n",
       "25%    4.457010e+05      24.000000            0.000000      23.000000   \n",
       "50%    9.251050e+05      39.000000            0.000000      51.000000   \n",
       "75%    1.192617e+06      51.000000            0.000000     136.000000   \n",
       "max    1.547874e+06     108.000000            1.000000     255.000000   \n",
       "\n",
       "             primary  primary_address  province_code  activity_index  \\\n",
       "count  134085.000000    134085.000000  134085.000000   134085.000000   \n",
       "mean        1.140702         0.994526      26.291353        0.462878   \n",
       "std         3.783715         0.104491      13.084682        0.504081   \n",
       "min        -1.000000        -1.000000      -1.000000       -1.000000   \n",
       "25%         1.000000         1.000000      15.000000        0.000000   \n",
       "50%         1.000000         1.000000      28.000000        0.000000   \n",
       "75%         1.000000         1.000000      34.000000        1.000000   \n",
       "max        99.000000         1.000000      52.000000        1.000000   \n",
       "\n",
       "       gross_income  day_diff_primary  day_diff_open  \n",
       "count  1.340850e+05     134085.000000  134085.000000  \n",
       "mean   1.340974e+05         -0.000582      81.670425  \n",
       "std    1.778989e+05          0.047455      68.020026  \n",
       "min    7.445640e+03         -6.000000       0.000000  \n",
       "25%    7.640391e+04          0.000000      23.000000  \n",
       "50%    1.232311e+05          0.000000      52.000000  \n",
       "75%    1.368992e+05          0.000000     140.000000  \n",
       "max    8.658967e+06          0.000000     259.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_info.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Definition and Feature of Accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned before.\n",
    "We define our target Y: {1: The costomer add the account, 0: the customer doesn't add the account}\n",
    "Therefore, we need to get the earliest opening date, which could help converting the accounts data to our target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In accounts table, we can get th historic accounts status of each clients. We want to extract the earlist date of each type of accounts the customer open. For example, If a clients added a saving account last month, the feature [saving_account_first] will be 1. if a clients added a tax account 2 months ago, [tax_account_first] will be 2 ,etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Y will be 1 if [account_first] is 0 and he opens the account this month. Target Y will be 0 for others which include a) clients who never opened the account and don't open account this month  b)clients who open the account before. Before training, we will filter b) clients by excluding the clients whose [account_first]>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_accounts['date']=pd.to_datetime(df_train_accounts['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_accounts2=df_train_accounts.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [01:32<00:00,  4.24s/it]\n"
     ]
    }
   ],
   "source": [
    "df_train_accounts['date']=pd.to_datetime(df_train_accounts['date'])\n",
    "for i in tqdm(list(df_train_accounts.columns)[3:]):\n",
    "    # look for the min date of opening the account. if a client never opened the account before, the feature will be 0.\n",
    "    df_date= df_train_accounts[df_train_accounts[i]==1].groupby('cust_id').date.min().reset_index().rename(index=str, columns={\"date\": i+'_first'})\n",
    "    df_train_accounts = df_train_accounts.merge(df_date,how='left',on='cust_id') \n",
    "    label_name= i+'_target'\n",
    "    new_i=i+'_first'\n",
    "    df_train_accounts[new_i]=pd.to_datetime(df_train_accounts [new_i])\n",
    "    df_train_accounts[new_i]=df_train_accounts['date'] - df_train_accounts[new_i]\n",
    "    df_train_accounts[new_i]=df_train_accounts[new_i].fillna(0)\n",
    "    df_train_accounts[new_i]=df_train_accounts[new_i].apply(lambda x: math.ceil(x.days/31))\n",
    "    df_train_accounts[new_i]=df_train_accounts[new_i].apply(lambda x: 0 if x <0 else x)\n",
    "    df_train_accounts[label_name]=df_train_accounts.apply(lambda x: 1 if (x[i] == 1 and x[new_i]==0) else 0,axis=1)\n",
    "df_train_accounts['date']=df_train_accounts['date'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_accounts['date']=df_train_accounts['date'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cust_id', 'cust_key', 'date', 'savings_account', 'guarantees',\n",
       "       'current_accounts', 'derived_account', 'payroll_account',\n",
       "       'junior_account', 'more_particular_account', 'particular_account',\n",
       "       'particular_plus_account', 'short_term_deposits',\n",
       "       'medium_term_deposits', 'long_term_deposits', 'e_account', 'funds',\n",
       "       'mortgage', 'pensions', 'loans', 'taxes', 'credit_card', 'securities',\n",
       "       'home_account', 'payroll', 'direct_debt', 'savings_account_first',\n",
       "       'savings_account_target', 'guarantees_first', 'guarantees_target',\n",
       "       'current_accounts_first', 'current_accounts_target',\n",
       "       'derived_account_first', 'derived_account_target',\n",
       "       'payroll_account_first', 'payroll_account_target',\n",
       "       'junior_account_first', 'junior_account_target',\n",
       "       'more_particular_account_first', 'more_particular_account_target',\n",
       "       'particular_account_first', 'particular_account_target',\n",
       "       'particular_plus_account_first', 'particular_plus_account_target',\n",
       "       'short_term_deposits_first', 'short_term_deposits_target',\n",
       "       'medium_term_deposits_first', 'medium_term_deposits_target',\n",
       "       'long_term_deposits_first', 'long_term_deposits_target',\n",
       "       'e_account_first', 'e_account_target', 'funds_first', 'funds_target',\n",
       "       'mortgage_first', 'mortgage_target', 'pensions_first',\n",
       "       'pensions_target', 'loans_first', 'loans_target', 'taxes_first',\n",
       "       'taxes_target', 'credit_card_first', 'credit_card_target',\n",
       "       'securities_first', 'securities_target', 'home_account_first',\n",
       "       'home_account_target', 'payroll_first', 'payroll_target',\n",
       "       'direct_debt_first', 'direct_debt_target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_accounts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill missing values of payroll accounts by 0\n",
    "df_train_accounts=df_train_accounts.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert month into month block.(eg. 2015-07-28 is 1, '2015-08-28' is 2, etc. )\n",
    "dates=list(df_train_accounts['date'].unique())\n",
    "df_train_accounts['month_block']=df_train_accounts['date'].apply(lambda x: dates.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge=df_train_accounts.merge(df_train_info2,how='left',on=['cust_id','date'])\n",
    "df_merge=df_merge.drop(['open_date','last_date_primary','province_code'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After feature engineering, we generate 410 features. A good feature selection is very helpful to reduce noise and get a high accuracy or recall. The following code is Mutual information used to do feature selection. We get top 50 features that has highest  Mutual information values for each label. By doing this loop for every label, we can get a set of good features, which will be applied into the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MI(topk,df,features, labels): \n",
    "    topk_features=[]\n",
    "    for label in tqdm(labels):\n",
    "        print(label)\n",
    "        scores=[]\n",
    "        for feature in features:\n",
    "            score=mutual_info_classif(df[[feature]],df[label])\n",
    "            scores.append(score[0])\n",
    "          #  print(feature, ':',score)\n",
    "        df_mi=pd.DataFrame({'features':features,'MI':scores})\n",
    "        topk_feature=df_mi.sort_values('MI',ascending= False)['features'][:topk]\n",
    "        topk_features.extend(list(topk_feature))\n",
    "    return list(set(topk_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "savings_account_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/23 [07:57<2:55:04, 477.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guarantees_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▊         | 2/23 [14:11<2:36:12, 446.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_accounts_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 3/23 [19:01<2:13:09, 399.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "derived_account_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 4/23 [23:54<1:56:27, 367.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payroll_account_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 5/23 [28:03<1:39:34, 331.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junior_account_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 6/23 [32:11<1:26:54, 306.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more_particular_account_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 7/23 [36:13<1:16:40, 287.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "particular_account_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▍      | 8/23 [40:32<1:09:43, 278.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "particular_plus_account_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 9/23 [45:02<1:04:24, 276.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short_term_deposits_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 10/23 [49:15<58:19, 269.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medium_term_deposits_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 11/23 [53:26<52:45, 263.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_term_deposits_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 12/23 [57:23<46:54, 255.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_account_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 13/23 [1:01:31<42:14, 253.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funds_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 14/23 [1:05:38<37:42, 251.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mortgage_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 15/23 [1:09:40<33:09, 248.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pensions_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 16/23 [1:13:34<28:29, 244.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loans_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 17/23 [1:17:39<24:26, 244.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxes_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 18/23 [1:21:36<20:10, 242.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credit_card_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 19/23 [1:25:41<16:12, 243.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "securities_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 20/23 [1:29:39<12:04, 241.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home_account_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████▏| 21/23 [1:33:36<08:00, 240.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payroll_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 22/23 [1:37:24<03:56, 236.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "direct_debt_target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [1:41:19<00:00, 236.12s/it]\n"
     ]
    }
   ],
   "source": [
    "features=MI(50,train,X_columns,targets_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deceased_status_-1',\n",
       " 'province_name_BIZKAIA',\n",
       " 'primary_address_1.0',\n",
       " 'channel_KHM',\n",
       " 'province_name_CACERES',\n",
       " 'channel_KAW',\n",
       " 'customer_relation_-1',\n",
       " 'province_name_CORDOBA',\n",
       " 'province_name_NAVARRA',\n",
       " 'province_name_PALMAS, LAS',\n",
       " 'province_name_CADIZ',\n",
       " 'channel_KCH',\n",
       " 'country_PA',\n",
       " 'province_name_CEUTA',\n",
       " 'last_6_months_flag_0.0',\n",
       " 'channel_KAT',\n",
       " 'channel_KFP',\n",
       " 'channel_KCA',\n",
       " 'province_name_TARRAGONA',\n",
       " 'channel_KHC',\n",
       " 'channel_KAG',\n",
       " 'activity_index_1.0',\n",
       " 'province_name_TOLEDO',\n",
       " 'junior_account_first',\n",
       " 'segment_02 - PARTICULARES',\n",
       " 'country_DE',\n",
       " 'foreigner_index_-1',\n",
       " 'derived_account_first',\n",
       " 'channel_KBS',\n",
       " 'customer_type_2',\n",
       " 'channel_KHK',\n",
       " 'sex_-1',\n",
       " 'channel_-1',\n",
       " 'country_MA',\n",
       " 'domestic_index_-1',\n",
       " 'segment_03 - UNIVERSITARIO',\n",
       " 'province_name_ALICANTE',\n",
       " 'province_name_ZAMORA',\n",
       " 'activity_index_0.0',\n",
       " 'credit_card_first',\n",
       " 'country_CN',\n",
       " 'province_name_SEVILLA',\n",
       " 'particular_account_first',\n",
       " 'province_name_GIRONA',\n",
       " 'channel_KAE',\n",
       " 'province_name_RIOJA, LA',\n",
       " 'country_AR',\n",
       " 'province_name_HUELVA',\n",
       " 'channel_KBO',\n",
       " 'sex_V',\n",
       " 'age',\n",
       " 'province_name_OURENSE',\n",
       " 'channel_KAY',\n",
       " 'channel_KFS',\n",
       " 'customer_type_P',\n",
       " 'channel_KCM',\n",
       " 'activity_index_-1.0',\n",
       " 'province_name_SORIA',\n",
       " 'province_name_SALAMANCA',\n",
       " 'country_NO',\n",
       " 'channel_KAR',\n",
       " 'channel_KHE',\n",
       " 'province_name_MADRID',\n",
       " 'segment_-1',\n",
       " 'province_name_GUADALAJARA',\n",
       " 'province_name_CUENCA',\n",
       " 'channel_KAA',\n",
       " 'seniority',\n",
       " 'country_EG',\n",
       " 'pensions_first',\n",
       " 'channel_KCG',\n",
       " 'customer_relation_A',\n",
       " 'channel_KEI',\n",
       " 'home_account_first',\n",
       " 'channel_KDV',\n",
       " 'customer_relation_I',\n",
       " 'country_ES',\n",
       " 'customer_type_2.0',\n",
       " 'province_name_CORUÑA, A',\n",
       " 'channel_KBF',\n",
       " 'country_FR',\n",
       " 'province_name_AVILA',\n",
       " 'loans_first',\n",
       " 'channel_KGV',\n",
       " 'channel_KEF',\n",
       " 'securities_first',\n",
       " 'province_name_ZARAGOZA',\n",
       " 'province_name_CANTABRIA',\n",
       " 'primary_-1.0',\n",
       " 'channel_KGY',\n",
       " 'country_SE',\n",
       " 'province_name_PALENCIA',\n",
       " 'channel_KFJ',\n",
       " 'deceased_status_N',\n",
       " 'channel_KEN',\n",
       " 'employee_index_N',\n",
       " 'channel_KFU',\n",
       " 'taxes_first',\n",
       " 'province_name_GIPUZKOA',\n",
       " 'customer_type_3.0',\n",
       " 'province_name_LEON',\n",
       " 'spouse_index_N',\n",
       " 'day_diff_open',\n",
       " 'country_US',\n",
       " 'channel_KCK',\n",
       " 'country_CH',\n",
       " 'channel_KAI',\n",
       " 'channel_KBU',\n",
       " 'channel_KFN',\n",
       " 'channel_KAC',\n",
       " 'channel_KEO',\n",
       " 'foreigner_index_N',\n",
       " 'country_CO',\n",
       " 'country_RO',\n",
       " 'channel_KCX',\n",
       " 'direct_debt_first',\n",
       " 'long_term_deposits_first',\n",
       " 'province_name_HUESCA',\n",
       " 'channel_KFG',\n",
       " 'current_accounts_first',\n",
       " 'customer_type_-1',\n",
       " 'payroll_first',\n",
       " 'province_name_VALLADOLID',\n",
       " 'province_name_SANTA CRUZ DE TENERIFE',\n",
       " 'payroll_account_first',\n",
       " 'channel_KHL',\n",
       " 'province_name_MALAGA',\n",
       " 'customer_relation_P',\n",
       " 'primary_1.0',\n",
       " 'channel_KEZ',\n",
       " 'country_GB',\n",
       " 'country_VE',\n",
       " 'channel_KFA',\n",
       " 'province_name_GRANADA',\n",
       " 'country_CL',\n",
       " 'channel_KCI',\n",
       " 'more_particular_account_first',\n",
       " 'province_name_CIUDAD REAL',\n",
       " 'customer_type_1.0',\n",
       " 'sex_H',\n",
       " 'channel_KED',\n",
       " 'channel_KHN',\n",
       " 'channel_KEH',\n",
       " 'particular_plus_account_first',\n",
       " 'province_name_BADAJOZ',\n",
       " 'province_name_MURCIA',\n",
       " 'channel_KFL',\n",
       " 'savings_account_first',\n",
       " 'channel_KCP',\n",
       " 'channel_KHQ',\n",
       " 'primary_99.0',\n",
       " 'e_account_first',\n",
       " 'customer_type_1',\n",
       " 'channel_KBR',\n",
       " 'country_MX',\n",
       " 'channel_KEJ',\n",
       " 'province_name_MELILLA',\n",
       " 'channel_KEL',\n",
       " 'funds_first',\n",
       " 'foreigner_index_S',\n",
       " 'last_6_months_flag_1.0',\n",
       " 'province_name_VALENCIA',\n",
       " 'channel_KDA',\n",
       " 'channel_KAB',\n",
       " 'spouse_index_-1',\n",
       " 'segment_01 - TOP',\n",
       " 'channel_007',\n",
       " 'channel_KAL',\n",
       " 'province_name_BALEARS, ILLES',\n",
       " 'employee_index_-1',\n",
       " 'channel_KDZ',\n",
       " 'gross_income',\n",
       " 'customer_type_3',\n",
       " 'customer_type_4.0',\n",
       " 'channel_KHF',\n",
       " 'country_BR',\n",
       " 'province_name_BURGOS',\n",
       " 'province_name_JAEN',\n",
       " 'last_6_months_flag_-1.0',\n",
       " 'channel_004',\n",
       " 'province_name_LUGO',\n",
       " 'country_EC',\n",
       " 'province_name_TERUEL',\n",
       " 'province_name_ASTURIAS',\n",
       " 'channel_KAH',\n",
       " 'domestic_index_S',\n",
       " 'mortgage_first',\n",
       " 'channel_KAF',\n",
       " 'employee_index_B',\n",
       " 'channel_KHD',\n",
       " 'channel_KFC',\n",
       " 'channel_KAD',\n",
       " 'channel_KCB',\n",
       " 'short_term_deposits_first',\n",
       " 'province_name_ALBACETE',\n",
       " 'province_name_BARCELONA']"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modelling & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I decided to use the random forest. The modell and feature engineering are operated on google cloud because the large dataset lead to a memory error if running locally.\n",
    "The reason why I choose random forest:\n",
    "\n",
    "\n",
    "1) Good performance. As a ensembling model, it reduced the variance to reduce overfitting. \n",
    "\n",
    "\n",
    "2) It also has a function of feature selection. we can evaluate the feature importance if we are asked to show the interpretability by stakeholders. \n",
    "\n",
    "\n",
    "3) It has parameter of clasee_weight, which we can use to balance our dataset. Also it support multi-label modelling, though we don't use it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the model, we mainly focus on a high recall, which equip us the ability to capture the clients behavior. Because the model is a recommendation system, instead of anti-fraud model, we don't have to ask for a low false positive(FP). But we still hope FP won't too high because of disturbing and cost. It's a trade-off. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model run on google cloud. The recall and FP result didn't showed here. But you can get the performance by evaluating my submission file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "for i in range(0,3): # Because memory restriction, we seperate the labels by three. \n",
    "    labels_names_sub=labels_names[8*i:8*(i+1)]\n",
    "    print(\"the ith 8 targets\",i)\n",
    "    for label_name in tqdm(labels_names_sub): # pick one label each time and train the model.\n",
    "        label_name_first=label_name+'_first'\n",
    "        label_name_target=label_name+'_target'\n",
    "        \n",
    "        # filter the training set and validation set\n",
    "        Y_block_14_ca=Y_block_14[X_block_14[label_name_first]==0]\n",
    "        Y_block_15_ca=Y_block_15[X_block_15[label_name_first]==0]\n",
    "        X_block_14_ca=X_block_14[X_block_14[label_name_first]==0]\n",
    "        X_block_15_ca=X_block_15[X_block_15[label_name_first]==0]\n",
    "        \n",
    "        #feature selection by feature importance\n",
    "        clf = RandomForestClassifier(n_estimators=600, max_depth=3,class_weight= 'balanced',random_state=88,n_jobs=-1)\n",
    "        clf.fit(X_block_14_ca,Y_block_14_ca[label_name_target])\n",
    "        feature_importance=pd.DataFrame({'name':list(X_block_14_ca.columns),'importance':clf.feature_importances_}).sort_values('importance',ascending=False)\n",
    "        # take best 100 features into the model\n",
    "        good_features=feature_importance['name'][0:100]\n",
    "        \n",
    "        # Train the model by 100 selected features \n",
    "        clf = RandomForestClassifier(n_estimators=600, max_depth=9,class_weight= 'balanced',random_state=88,n_jobs=-1)\n",
    "        clf.fit(X_block_14_ca[good_features],Y_block_14_ca[label_name_target])\n",
    "        \n",
    "        # predict the label\n",
    "        y_pred = clf.predict(X_block_15_ca[good_features])\n",
    "        \n",
    "        #calculate the recall of the label.\n",
    "        recall=recall_score(Y_block_15_ca[label_name_target],y_pred)\n",
    "        print(label_name_target,Y_block_15_ca[label_name_target].sum(),y_pred.sum(),recall)\n",
    "        y_pred_prob = clf.predict_proba(X_block_16[good_features])\n",
    "        Y_block_16[label_name_target]=y_pred_prob[:,-1]\n",
    "    labels_names_sub.append('cust_id')\n",
    "    #save the result\n",
    "    Y_block_16.iloc[:,8*i:8*(i+1)].to_csv('sub_result_final'+str(i)+'.csv',index=True, header=True)\n",
    "    print('successful save file'+'sub_result_final'+str(i)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "def recall(y_test,y_pred):\n",
    "    recalls=[]\n",
    "    for i in range(y_test.shape[1]):\n",
    "        recall=recall_score(y_test.iloc[:,i],y_pred[:,i])\n",
    "        recalls.append(recall)\n",
    "        #print(recall)\n",
    "        average=np.mean(recalls)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_business(x):\n",
    "    sorted_buss=x[1:-1].sort_values(ascending=False)\n",
    "    business = sorted_buss[sorted_buss>0.5].index.tolist()\n",
    "    if len(business)==0:\n",
    "        business.append(sorted_buss.index[0])\n",
    "    return '; '.join(business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_int['products']=result_int.apply(get_business,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_int[['cust_id','products']].to_csv('{Peter_Chen}_predictions2.csv',index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions & Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\tProvide a brief summary at the end to explain the additional steps you could have taken to increase your model(s) ability to make correct predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is applicable in the business of banks. It doesn't require a high GPU to maintain and save the conputation resouce. Also, in terms of interpretability, the model could give an insight to show key factors to affect a product. In addition, each label has it's own model, different label of business line won't affect each other but shared the same features, which allowed us to maintain and update each product model easily. The logic method applied in the case is to transer a time-series problem into classification problem. It's the key to define the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measures taken to improve the model:\n",
    "\n",
    "1) Hyper parameter tuning. Because of large dateset and limited computation resource, I didn't do a lot of hyper papameter tuning. Train the model with more samples will reduce overfitting but require more computation resource. A distributed system can easily solve the problem and allow us to do hyper parameter tuning.\n",
    "\n",
    "2)Generate more features. Explore more on the bin-feature and select the features carefully for each labels and models will definetly be helpful. \n",
    "\n",
    "3) Model Stacking. It's a very common method applied in kaggle competition. We can also build a user-user recommendation system to predict the product. Average the predicting probability will increase the score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\tWhich part of the business process could you apply this predictive model to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation system\n",
    "\n",
    "This model is able to predict the demand of the clients next month based on historic data and demographic data. For high True positive labels, we can ask clients representative to have a cold call, which is very helpful in improving the conversion rate of clients. For low true positive labels, we can send email or push app notification, which is able to save money in marketing.\n",
    "\n",
    "Business process:\n",
    "\n",
    "1. Cold Start. When a new client opens the account in our bank, we can introduce him the predicted products.\n",
    "\n",
    "2. Marketing. When we have a new promotion on some specific product, we can send the notification to the labeled clients and avoiding disturbing the clients without interest.\n",
    "\n",
    "3. Cold call. The model can make cold call of sales more efficient and also enable telephone customer service to know better the clients.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
